Although the primary goal of our paper is to \textit{understand} what drives memorability of objects in a scene, the current work also makes available the very first dataset containing the ground truth memorability of constituent objects from a highly diverse image set. In this section, we show that our dataset can serve as a  benchmark for the purpose of object memorability prediction by making use of the ground truth memorability maps constructed from experimental data.

\textbf{Baseline models:} As a first step, we propose a simple baseline model that utilizes a conv-net \cite{krizhevsky12}, \cite{jia14} trained on the ImageNet database \cite{deng09} . Since object categories play an important role in determining object memorability (\ref{sec:obLabel}), and deep learning models have recently been shown to achieve state-of-the-art results in various other recognition tasks, including object recognition and object categorization (cite papers here), we believe that this simple model can serve as a good initial baseline model for object memorability prediction. We first generated object segments by using MCG, a generic object proposal method proposed in \cite{arbelaez14}. Next, we trained an SVR using $6$-fold cross-validation on the original segments to map deep features to memorability scores. We then used this model to predict the memorability scores for the top K ($K=20$) segments (obtained via the ranking scores provided by the MCG algorithm) for each image. After obtaining the predicted memorability scores, the memorability maps were generated by averaging the top $K$ segments at the pixel level.

Since image features like SIFT \cite{lowe04} and HOG \cite{dalal05} have previously been shown to achieve good performance in predicting image memorability, we built another baseline model using these features. Training and testing of this model was performed similar to the deep-net baseline model. 

\textbf{Evaluation: } To evaluate the accuracy of the predicted memorability maps, we calculate the mean predicted memorability score inside each of the original object segments and do a rank correlation with respect to their ground memorability scores. We also include $8$ state-of-the-art-saliency methods (some of these are the top performing methods according to benchmarks in cite benchmarks) to our comparison. Given our findings from section [saliency section], the purpose of inclusion of these methods to the comparison is to test how well can a simple Note firstly that our deep learning baseline model performs considerably well (cite final number). For comparison, we show the results of a simpler model trained using only HOG and SIFT features, which are also likely to capture aspects of different object categories, but exhibit lower overall performance than deep features. While our deep network model performed fairly well, part of the performance of such a model is dependent on the quality of the segmentations, which is best framed as being solely independent of the task of inferring memorability of a region. For this reason, we consider the upper bound of our current predictive power by showing the results for another deep learning model containing predictions for the original segments. Interestingly, the accuracy of this model is very high, suggesting that our model has high predictive ability that is suppressed most heavily by constraints of the segmentation task. Lastly, as a proof of concept that informative maps (ie. saliency, memorability) can be compared across domains, we show the predictive utility of some of the recent state-of-the-art saliency algorithms applied to the task of identifying memorable regions. Results follow from the previously-found link between object-sparse images and saliency.

\begin{figure}[t]
\centering
\subfigure{\centering \includegraphics[width=0.4\textwidth]{figures/results/benchmark/comparison.png}}
\vspace{-5mm}\caption{\footnotesize\textbf{Main task.} add-in later. }\label{fig:benchmark}
\end{figure}